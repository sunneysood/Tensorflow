{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Horses Vs Human Transfer Learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sunneysood/Tensorflow/blob/master/Horses_Vs_Human_Transfer_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbFmQdsZs5eW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 62
        },
        "outputId": "1af23b6a-321c-4999-d809-31086c34dd7a"
      },
      "source": [
        "# Import all the necessary files!\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1xJZ5glPPCRz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "be7ff83e-59ac-43ba-8d9a-acf12ec67050"
      },
      "source": [
        "# Download the inception v3 weights\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
        "\n",
        "# Import the inception model  \n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "# Create an instance of the inception model from the local pre-trained weights\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "pre_trained_model = InceptionV3(input_shape = (150, 150, 3), \n",
        "                                include_top = False, \n",
        "                                weights = None)\n",
        "\n",
        "pre_trained_model.load_weights(local_weights_file)\n",
        "\n",
        "# Make all the layers in the pre-trained model non-trainable\n",
        "for layer in pre_trained_model.layers:\n",
        "  # Your Code Here\n",
        "  layer.trainable=False\n",
        "  \n",
        "# Print the model summary\n",
        "pre_trained_model.summary()\n",
        "\n",
        "# Expected Output is extremely large, but should end with:\n",
        "\n",
        "#batch_normalization_v1_281 (Bat (None, 3, 3, 192)    576         conv2d_281[0][0]                 \n",
        "#__________________________________________________________________________________________________\n",
        "#activation_273 (Activation)     (None, 3, 3, 320)    0           batch_normalization_v1_273[0][0] \n",
        "#__________________________________________________________________________________________________\n",
        "#mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_275[0][0]             \n",
        "#                                                                 activation_276[0][0]             \n",
        "#__________________________________________________________________________________________________\n",
        "#concatenate_5 (Concatenate)     (None, 3, 3, 768)    0           activation_279[0][0]             \n",
        "#                                                                 activation_280[0][0]             \n",
        "#__________________________________________________________________________________________________\n",
        "#activation_281 (Activation)     (None, 3, 3, 192)    0           batch_normalization_v1_281[0][0] \n",
        "#__________________________________________________________________________________________________\n",
        "#mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_273[0][0]             \n",
        "#                                                                 mixed9_1[0][0]                   \n",
        "#                                                                 concatenate_5[0][0]              \n",
        "#                                                                 activation_281[0][0]             \n",
        "#==================================================================================================\n",
        "#Total params: 21,802,784\n",
        "#Trainable params: 0\n",
        "#Non-trainable params: 21,802,784"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-11-17 05:57:55--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.20.128, 2607:f8b0:400e:c09::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.20.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87910968 (84M) [application/x-hdf]\n",
            "Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
            "\n",
            "/tmp/inception_v3_w 100%[===================>]  83.84M  95.0MB/s    in 0.9s    \n",
            "\n",
            "2019-11-17 05:57:56 (95.0 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Model: \"inception_v3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 7, 7, 192)    576         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 7, 7, 192)    0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 7, 7, 192)    258048      activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 7, 7, 192)    576         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 7, 7, 192)    0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 7, 7, 192)    258048      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 7, 7, 192)    576         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 7, 7, 192)    576         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 7, 7, 192)    0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 7, 7, 192)    0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 3, 3, 320)    552960      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 3, 3, 192)    331776      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 3, 3, 320)    960         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 3, 3, 192)    576         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 3, 3, 320)    0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 3, 3, 192)    0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 3, 3, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 3, 3, 1280)   0           activation_71[0][0]              \n",
            "                                                                 activation_75[0][0]              \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 3, 3, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 3, 3, 448)    1344        conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 3, 3, 448)    0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 3, 3, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 3, 3, 384)    1548288     activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 3, 3, 384)    1152        conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 3, 3, 384)    1152        conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 3, 3, 384)    0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 3, 3, 384)    0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 3, 3, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 3, 3, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 3, 3, 384)    1152        conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 3, 3, 384)    1152        conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 3, 3, 384)    1152        conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 3, 3, 384)    1152        conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 3, 3, 192)    245760      average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 3, 3, 320)    960         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 3, 3, 384)    0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 3, 3, 384)    0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 3, 3, 384)    0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 3, 3, 384)    0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 3, 3, 192)    576         conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 3, 3, 320)    0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 3, 3, 768)    0           activation_78[0][0]              \n",
            "                                                                 activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 3, 3, 768)    0           activation_82[0][0]              \n",
            "                                                                 activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 3, 3, 192)    0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 3, 3, 2048)   0           activation_76[0][0]              \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate[0][0]                \n",
            "                                                                 activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 3, 3, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 3, 3, 448)    1344        conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 3, 3, 448)    0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 3, 3, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 3, 3, 384)    1548288     activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 3, 3, 384)    1152        conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 3, 3, 384)    1152        conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 3, 3, 384)    0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 3, 3, 384)    0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 3, 3, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 3, 3, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 3, 3, 384)    1152        conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 3, 3, 384)    1152        conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 3, 3, 384)    1152        conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 3, 3, 384)    1152        conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 3, 3, 192)    393216      average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 3, 3, 320)    960         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 3, 3, 384)    0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 3, 3, 384)    0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 3, 3, 384)    0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 3, 3, 384)    0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 3, 3, 192)    576         conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 3, 3, 320)    0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_87[0][0]              \n",
            "                                                                 activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 3, 3, 768)    0           activation_91[0][0]              \n",
            "                                                                 activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 3, 3, 192)    0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_85[0][0]              \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_1[0][0]              \n",
            "                                                                 activation_93[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 21,802,784\n",
            "Trainable params: 0\n",
            "Non-trainable params: 21,802,784\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFsUlwdfs_wg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "62179149-2772-4bec-8f3a-15fa1fcd21c3"
      },
      "source": [
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "print('last layer output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output\n",
        "\n",
        "# Expected Output:\n",
        "# ('last layer output shape: ', (None, 7, 7, 768))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "last layer output shape:  (None, 7, 7, 768)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bsWZWp5oMq9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a Callback class that stops training once accuracy reaches 99.9%\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('acc')>0.999):\n",
        "      print(\"\\nReached 99.9% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BMXb913pbvFg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5cb93e89-da1b-4c39-d93a-3b5f3d4a6932"
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(last_output)\n",
        "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "# Add a dropout rate of 0.2\n",
        "x = layers.Dropout(0.2)(x)                  \n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense  (1,activation='sigmoid')(x)           \n",
        "\n",
        "model = Model(pre_trained_model.input, x) \n",
        "\n",
        "model.compile(optimizer = RMSprop(lr=0.0001), \n",
        "              loss = 'binary_crossentropy', \n",
        "              metrics = ['acc'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Expected output will be large. Last few lines should be:\n",
        "\n",
        "# mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_248[0][0]             \n",
        "#                                                                  activation_251[0][0]             \n",
        "#                                                                  activation_256[0][0]             \n",
        "#                                                                  activation_257[0][0]             \n",
        "# __________________________________________________________________________________________________\n",
        "# flatten_4 (Flatten)             (None, 37632)        0           mixed7[0][0]                     \n",
        "# __________________________________________________________________________________________________\n",
        "# dense_8 (Dense)                 (None, 1024)         38536192    flatten_4[0][0]                  \n",
        "# __________________________________________________________________________________________________\n",
        "# dropout_4 (Dropout)             (None, 1024)         0           dense_8[0][0]                    \n",
        "# __________________________________________________________________________________________________\n",
        "# dense_9 (Dense)                 (None, 1)            1025        dropout_4[0][0]                  \n",
        "# ==================================================================================================\n",
        "# Total params: 47,512,481\n",
        "# Trainable params: 38,537,217\n",
        "# Non-trainable params: 8,975,264\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 37632)        0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 1024)         38536192    flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 1024)         0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 1)            1025        dropout_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 47,512,481\n",
            "Trainable params: 38,537,217\n",
            "Non-trainable params: 8,975,264\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrnL_IQ8knWA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "outputId": "736e7fe5-218b-4a33-bd08-48775aeea8fd"
      },
      "source": [
        "# Get the Horse or Human dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip -O /tmp/horse-or-human.zip\n",
        "\n",
        "# Get the Horse or Human Validation dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip -O /tmp/validation-horse-or-human.zip \n",
        "  \n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '//tmp/horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/training')\n",
        "zip_ref.close()\n",
        "\n",
        "local_zip = '//tmp/validation-horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/validation')\n",
        "zip_ref.close()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-11-17 06:03:07--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.195.128, 2607:f8b0:400e:c08::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.195.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 149574867 (143M) [application/zip]\n",
            "Saving to: ‘/tmp/horse-or-human.zip’\n",
            "\n",
            "/tmp/horse-or-human 100%[===================>] 142.65M  93.0MB/s    in 1.5s    \n",
            "\n",
            "2019-11-17 06:03:09 (93.0 MB/s) - ‘/tmp/horse-or-human.zip’ saved [149574867/149574867]\n",
            "\n",
            "--2019-11-17 06:03:10--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.142.128, 2607:f8b0:400e:c09::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.142.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11480187 (11M) [application/zip]\n",
            "Saving to: ‘/tmp/validation-horse-or-human.zip’\n",
            "\n",
            "/tmp/validation-hor 100%[===================>]  10.95M  54.9MB/s    in 0.2s    \n",
            "\n",
            "2019-11-17 06:03:11 (54.9 MB/s) - ‘/tmp/validation-horse-or-human.zip’ saved [11480187/11480187]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9okX7_ovskI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "80f3e7d0-83cf-4e54-9316-4c7e2eb4e5ef"
      },
      "source": [
        "base_dir = '/tmp'\n",
        "train_dir = os.path.join( base_dir, 'training')\n",
        "validation_dir = os.path.join( base_dir, 'validation')\n",
        "\n",
        "train_horses_dir = os.path.join(train_dir,'horses')\n",
        "train_humans_dir = os.path.join(train_dir,'humans')\n",
        "validation_horses_dir = os.path.join(validation_dir,'horses')\n",
        "validation_humans_dir = os.path.join(validation_dir,'humans')\n",
        "\n",
        "train_horses_fnames = os.listdir(train_horses_dir)\n",
        "train_humans_fnames = os.listdir(train_humans_dir)\n",
        "validation_horses_fnames = os.listdir(validation_horses_dir)\n",
        "validation_humans_fnames = os.listdir(validation_horses_dir)\n",
        "\n",
        "print(len(train_horses_fnames))\n",
        "print(len(train_humans_fnames))\n",
        "print(len(validation_horses_fnames))\n",
        "print(len(validation_humans_fnames))\n",
        "\n",
        "# Expected Output:\n",
        "# 500\n",
        "# 527\n",
        "# 128\n",
        "# 128"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "500\n",
            "527\n",
            "128\n",
            "128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O4s8HckqGlnb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "1e57be6a-71e6-4581-ca4d-ef12060dffca"
      },
      "source": [
        "# Define our example directories and files\n",
        "train_dir = '/tmp/training'\n",
        "validation_dir = '/tmp/validation'\n",
        "\n",
        "# Add our data-augmentation parameters to ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255.,\n",
        "                                   rotation_range = 40,\n",
        "                                   width_shift_range = 0.2,\n",
        "                                   height_shift_range = 0.2,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255. )\n",
        "\n",
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    batch_size = 20,\n",
        "                                                    class_mode = 'binary', \n",
        "                                                    target_size = (150, 150))     \n",
        "\n",
        "# Flow validation images in batches of 20 using test_datagen generator\n",
        "validation_generator =  test_datagen.flow_from_directory( validation_dir,\n",
        "                                                    batch_size = 20,\n",
        "                                                    class_mode = 'binary', \n",
        "                                                    target_size = (150, 150))\n",
        "\n",
        "# Expected Output:\n",
        "# Found 1027 images belonging to 2 classes.\n",
        "# Found 256 images belonging to 2 classes."
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1027 images belonging to 2 classes.\n",
            "Found 256 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Blhq2MAUeyGA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0b75839d-fc90-4be6-d330-e26b18678522"
      },
      "source": [
        "# Run this and see how many epochs it should take before the callback\n",
        "# fires, and stops training at 99.9% accuracy\n",
        "# (It should take less than 100 epochs)\n",
        "\n",
        "callbacks = myCallback()\n",
        "history = model.fit_generator(train_generator,\n",
        "            validation_data = validation_generator,\n",
        "            steps_per_epoch = 100,\n",
        "            epochs = 100,\n",
        "            validation_steps = 50,\n",
        "            verbose = 2,\n",
        "            callbacks=[callbacks])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "Epoch 1/100\n",
            "100/100 - 27s - loss: 0.2161 - acc: 0.9108 - val_loss: 0.0105 - val_acc: 0.9960\n",
            "Epoch 2/100\n",
            "Epoch 1/100\n",
            "100/100 - 22s - loss: 0.0637 - acc: 0.9726 - val_loss: 0.0143 - val_acc: 0.9929\n",
            "Epoch 3/100\n",
            "Epoch 1/100\n",
            "100/100 - 21s - loss: 0.0321 - acc: 0.9848 - val_loss: 0.0013 - val_acc: 1.0000\n",
            "Epoch 4/100\n",
            "Epoch 1/100\n",
            "100/100 - 21s - loss: 0.0375 - acc: 0.9889 - val_loss: 0.0085 - val_acc: 0.9970\n",
            "Epoch 5/100\n",
            "Epoch 1/100\n",
            "100/100 - 20s - loss: 0.0462 - acc: 0.9848 - val_loss: 0.0646 - val_acc: 0.9879\n",
            "Epoch 6/100\n",
            "Epoch 1/100\n",
            "100/100 - 20s - loss: 0.0290 - acc: 0.9853 - val_loss: 0.3967 - val_acc: 0.9524\n",
            "Epoch 7/100\n",
            "Epoch 1/100\n",
            "100/100 - 20s - loss: 0.0236 - acc: 0.9913 - val_loss: 0.1879 - val_acc: 0.9696\n",
            "Epoch 8/100\n",
            "Epoch 1/100\n",
            "100/100 - 21s - loss: 0.0350 - acc: 0.9879 - val_loss: 0.0781 - val_acc: 0.9879\n",
            "Epoch 9/100\n",
            "Epoch 1/100\n",
            "100/100 - 20s - loss: 0.0262 - acc: 0.9913 - val_loss: 0.0785 - val_acc: 0.9879\n",
            "Epoch 10/100\n",
            "Epoch 1/100\n",
            "100/100 - 20s - loss: 0.0339 - acc: 0.9909 - val_loss: 0.0621 - val_acc: 0.9919\n",
            "Epoch 11/100\n",
            "Epoch 1/100\n",
            "100/100 - 21s - loss: 0.0403 - acc: 0.9904 - val_loss: 0.0552 - val_acc: 0.9889\n",
            "Epoch 12/100\n",
            "Epoch 1/100\n",
            "100/100 - 20s - loss: 0.0303 - acc: 0.9919 - val_loss: 0.0351 - val_acc: 0.9919\n",
            "Epoch 13/100\n",
            "Epoch 1/100\n",
            "100/100 - 21s - loss: 0.0202 - acc: 0.9929 - val_loss: 0.2184 - val_acc: 0.9626\n",
            "Epoch 14/100\n",
            "Epoch 1/100\n",
            "100/100 - 20s - loss: 0.0137 - acc: 0.9939 - val_loss: 0.1064 - val_acc: 0.9889\n",
            "Epoch 15/100\n",
            "Epoch 1/100\n",
            "100/100 - 21s - loss: 0.0255 - acc: 0.9970 - val_loss: 0.0076 - val_acc: 0.9960\n",
            "Epoch 16/100\n",
            "Epoch 1/100\n",
            "100/100 - 21s - loss: 0.0263 - acc: 0.9939 - val_loss: 0.0336 - val_acc: 0.9960\n",
            "Epoch 17/100\n",
            "Epoch 1/100\n",
            "100/100 - 20s - loss: 0.0207 - acc: 0.9934 - val_loss: 0.1927 - val_acc: 0.9717\n",
            "Epoch 18/100\n",
            "Epoch 1/100\n",
            "100/100 - 21s - loss: 0.0074 - acc: 0.9970 - val_loss: 0.1443 - val_acc: 0.9798\n",
            "Epoch 19/100\n",
            "Epoch 1/100\n",
            "100/100 - 21s - loss: 0.0315 - acc: 0.9919 - val_loss: 0.2431 - val_acc: 0.9676\n",
            "Epoch 20/100\n",
            "Epoch 1/100\n",
            "100/100 - 21s - loss: 0.0275 - acc: 0.9939 - val_loss: 0.2820 - val_acc: 0.9646\n",
            "Epoch 21/100\n",
            "Epoch 1/100\n",
            "100/100 - 21s - loss: 0.0154 - acc: 0.9955 - val_loss: 0.2381 - val_acc: 0.9727\n",
            "Epoch 22/100\n",
            "Epoch 1/100\n",
            "100/100 - 20s - loss: 0.0156 - acc: 0.9949 - val_loss: 0.1144 - val_acc: 0.9889\n",
            "Epoch 23/100\n",
            "Epoch 1/100\n",
            "100/100 - 21s - loss: 0.0105 - acc: 0.9965 - val_loss: 0.2442 - val_acc: 0.9717\n",
            "Epoch 24/100\n",
            "Epoch 1/100\n",
            "100/100 - 21s - loss: 0.0071 - acc: 0.9985 - val_loss: 0.9692 - val_acc: 0.9362\n",
            "Epoch 25/100\n",
            "Epoch 1/100\n",
            "100/100 - 20s - loss: 0.0178 - acc: 0.9944 - val_loss: 0.6533 - val_acc: 0.9474\n",
            "Epoch 26/100\n",
            "Epoch 1/100\n",
            "100/100 - 20s - loss: 0.0327 - acc: 0.9934 - val_loss: 0.2827 - val_acc: 0.9686\n",
            "Epoch 27/100\n",
            "Epoch 1/100\n",
            "100/100 - 20s - loss: 0.0226 - acc: 0.9954 - val_loss: 0.3510 - val_acc: 0.9615\n",
            "Epoch 28/100\n",
            "Epoch 1/100\n",
            "100/100 - 22s - loss: 0.0146 - acc: 0.9965 - val_loss: 0.5900 - val_acc: 0.9585\n",
            "Epoch 29/100\n",
            "Epoch 1/100\n",
            "100/100 - 21s - loss: 0.0088 - acc: 0.9975 - val_loss: 0.6510 - val_acc: 0.9524\n",
            "Epoch 30/100\n",
            "Epoch 1/100\n",
            "100/100 - 21s - loss: 0.0336 - acc: 0.9929 - val_loss: 0.8003 - val_acc: 0.9494\n",
            "Epoch 31/100\n",
            "Epoch 1/100\n",
            "100/100 - 21s - loss: 0.0095 - acc: 0.9970 - val_loss: 0.9581 - val_acc: 0.9433\n",
            "Epoch 32/100\n",
            "Epoch 1/100\n",
            "100/100 - 21s - loss: 0.0136 - acc: 0.9965 - val_loss: 0.7819 - val_acc: 0.9524\n",
            "Epoch 33/100\n",
            "Epoch 1/100\n",
            "100/100 - 20s - loss: 0.0242 - acc: 0.9954 - val_loss: 0.6152 - val_acc: 0.9555\n",
            "Epoch 34/100\n",
            "Epoch 1/100\n",
            "100/100 - 21s - loss: 0.0154 - acc: 0.9970 - val_loss: 0.9199 - val_acc: 0.9433\n",
            "Epoch 35/100\n",
            "Epoch 1/100\n",
            "100/100 - 21s - loss: 0.0199 - acc: 0.9949 - val_loss: 0.3185 - val_acc: 0.9595\n",
            "Epoch 36/100\n",
            "Epoch 1/100\n",
            "100/100 - 20s - loss: 0.0076 - acc: 0.9990 - val_loss: 0.4779 - val_acc: 0.9555\n",
            "Epoch 37/100\n",
            "Epoch 1/100\n",
            "100/100 - 20s - loss: 0.0134 - acc: 0.9970 - val_loss: 0.5571 - val_acc: 0.9595\n",
            "Epoch 38/100\n",
            "Epoch 1/100\n",
            "100/100 - 20s - loss: 0.0238 - acc: 0.9944 - val_loss: 0.8872 - val_acc: 0.9443\n",
            "Epoch 39/100\n",
            "Epoch 1/100\n",
            "100/100 - 20s - loss: 0.0107 - acc: 0.9965 - val_loss: 0.8554 - val_acc: 0.9474\n",
            "Epoch 40/100\n",
            "Epoch 1/100\n",
            "100/100 - 20s - loss: 0.0249 - acc: 0.9954 - val_loss: 1.1310 - val_acc: 0.9393\n",
            "Epoch 41/100\n",
            "Epoch 1/100\n",
            "100/100 - 21s - loss: 0.0079 - acc: 0.9980 - val_loss: 0.4091 - val_acc: 0.9615\n",
            "Epoch 42/100\n",
            "Epoch 1/100\n",
            "100/100 - 21s - loss: 0.0111 - acc: 0.9965 - val_loss: 0.4694 - val_acc: 0.9615\n",
            "Epoch 43/100\n",
            "Epoch 1/100\n",
            "100/100 - 21s - loss: 0.0123 - acc: 0.9959 - val_loss: 0.6556 - val_acc: 0.9514\n",
            "Epoch 44/100\n",
            "Epoch 1/100\n",
            "100/100 - 21s - loss: 0.0253 - acc: 0.9955 - val_loss: 0.5595 - val_acc: 0.9595\n",
            "Epoch 45/100\n",
            "Epoch 1/100\n",
            "100/100 - 20s - loss: 0.0145 - acc: 0.9964 - val_loss: 0.6242 - val_acc: 0.9575\n",
            "Epoch 46/100\n",
            "Epoch 1/100\n",
            "100/100 - 20s - loss: 0.0077 - acc: 0.9980 - val_loss: 0.3511 - val_acc: 0.9605\n",
            "Epoch 47/100\n",
            "Epoch 1/100\n",
            "100/100 - 20s - loss: 0.0125 - acc: 0.9944 - val_loss: 0.7472 - val_acc: 0.9565\n",
            "Epoch 48/100\n",
            "Epoch 1/100\n",
            "100/100 - 20s - loss: 0.0138 - acc: 0.9970 - val_loss: 0.8152 - val_acc: 0.9494\n",
            "Epoch 49/100\n",
            "Epoch 1/100\n",
            "100/100 - 20s - loss: 0.0261 - acc: 0.9954 - val_loss: 0.4655 - val_acc: 0.9565\n",
            "Epoch 50/100\n",
            "Epoch 1/100\n",
            "100/100 - 20s - loss: 0.0144 - acc: 0.9975 - val_loss: 0.4178 - val_acc: 0.9575\n",
            "Epoch 51/100\n",
            "Epoch 1/100\n",
            "100/100 - 21s - loss: 0.0070 - acc: 0.9975 - val_loss: 0.8661 - val_acc: 0.9534\n",
            "Epoch 52/100\n",
            "Epoch 1/100\n",
            "100/100 - 20s - loss: 0.0175 - acc: 0.9975 - val_loss: 0.1741 - val_acc: 0.9838\n",
            "Epoch 53/100\n",
            "Epoch 1/100\n",
            "100/100 - 20s - loss: 0.0077 - acc: 0.9980 - val_loss: 0.7319 - val_acc: 0.9595\n",
            "Epoch 54/100\n",
            "Epoch 1/100\n",
            "100/100 - 21s - loss: 0.0186 - acc: 0.9959 - val_loss: 0.4892 - val_acc: 0.9676\n",
            "Epoch 55/100\n",
            "Epoch 1/100\n",
            "100/100 - 21s - loss: 0.0158 - acc: 0.9980 - val_loss: 0.9056 - val_acc: 0.9474\n",
            "Epoch 56/100\n",
            "Epoch 1/100\n",
            "100/100 - 20s - loss: 0.0090 - acc: 0.9970 - val_loss: 1.5621 - val_acc: 0.9261\n",
            "Epoch 57/100\n",
            "Epoch 1/100\n",
            "100/100 - 20s - loss: 0.0081 - acc: 0.9980 - val_loss: 0.5518 - val_acc: 0.9666\n",
            "Epoch 58/100\n",
            "Epoch 1/100\n",
            "100/100 - 21s - loss: 0.0239 - acc: 0.9970 - val_loss: 0.6868 - val_acc: 0.9626\n",
            "Epoch 59/100\n",
            "Epoch 1/100\n",
            "100/100 - 21s - loss: 0.0064 - acc: 0.9980 - val_loss: 0.8280 - val_acc: 0.9575\n",
            "Epoch 60/100\n",
            "Epoch 1/100\n",
            "100/100 - 20s - loss: 0.0142 - acc: 0.9959 - val_loss: 0.8842 - val_acc: 0.9565\n",
            "Epoch 61/100\n",
            "Epoch 1/100\n",
            "100/100 - 20s - loss: 0.0089 - acc: 0.9965 - val_loss: 0.7068 - val_acc: 0.9686\n",
            "Epoch 62/100\n",
            "Epoch 1/100\n",
            "100/100 - 20s - loss: 0.0092 - acc: 0.9959 - val_loss: 0.6884 - val_acc: 0.9656\n",
            "Epoch 63/100\n",
            "Epoch 1/100\n",
            "100/100 - 20s - loss: 0.0125 - acc: 0.9959 - val_loss: 0.9928 - val_acc: 0.9524\n",
            "Epoch 64/100\n",
            "Epoch 1/100\n",
            "100/100 - 20s - loss: 0.0054 - acc: 0.9975 - val_loss: 1.1258 - val_acc: 0.9464\n",
            "Epoch 65/100\n",
            "Epoch 1/100\n",
            "100/100 - 20s - loss: 0.0053 - acc: 0.9985 - val_loss: 0.8149 - val_acc: 0.9615\n",
            "Epoch 66/100\n",
            "Epoch 1/100\n",
            "100/100 - 20s - loss: 0.0022 - acc: 0.9990 - val_loss: 1.0702 - val_acc: 0.9534\n",
            "Epoch 67/100\n",
            "Epoch 1/100\n",
            "100/100 - 21s - loss: 0.0101 - acc: 0.9975 - val_loss: 1.3458 - val_acc: 0.9433\n",
            "Epoch 68/100\n",
            "Epoch 1/100\n",
            "100/100 - 21s - loss: 0.0103 - acc: 0.9975 - val_loss: 1.2304 - val_acc: 0.9534\n",
            "Epoch 69/100\n",
            "Epoch 1/100\n",
            "100/100 - 20s - loss: 0.0011 - acc: 0.9990 - val_loss: 1.0576 - val_acc: 0.9575\n",
            "Epoch 70/100\n",
            "Epoch 1/100\n",
            "100/100 - 20s - loss: 0.0282 - acc: 0.9960 - val_loss: 1.0240 - val_acc: 0.9565\n",
            "Epoch 71/100\n",
            "Epoch 1/100\n",
            "100/100 - 20s - loss: 0.0038 - acc: 0.9990 - val_loss: 1.4738 - val_acc: 0.9332\n",
            "Epoch 72/100\n",
            "Epoch 1/100\n",
            "100/100 - 20s - loss: 0.0335 - acc: 0.9965 - val_loss: 1.2510 - val_acc: 0.9474\n",
            "Epoch 73/100\n",
            "Epoch 1/100\n",
            "100/100 - 20s - loss: 0.0169 - acc: 0.9970 - val_loss: 1.7951 - val_acc: 0.9251\n",
            "Epoch 74/100\n",
            "Epoch 1/100\n",
            "100/100 - 20s - loss: 0.0120 - acc: 0.9970 - val_loss: 1.4169 - val_acc: 0.9372\n",
            "Epoch 75/100\n",
            "Epoch 1/100\n",
            "\n",
            "Reached 99.9% accuracy so cancelling training!\n",
            "100/100 - 21s - loss: 9.7226e-04 - acc: 0.9995 - val_loss: 0.9155 - val_acc: 0.9595\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2Fp6Se9rKuL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "69725cd9-58f7-4a0d-c0ca-be18f3f72e97"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wH0F-__HXDa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}